# Data Exploration and Processing

This folder contains Jupyter notebooks used for exploring and processing the dataset in the NTTData Healthcare Challenge project.

## Contents

### 1. initial_exploring.ipynb
- This notebook comprises initial explorations and graphical representations of the dataset. It provides an initial overview and visual insights into the data.

### 2. data_processingNo23.ipynb
- The notebook focuses on preprocessing the dataset, separating it into two distinct CSV files. One contains products purchased before 2023, and the other includes products purchased after 2023.

### 3. creating_product_category.ipynb
- This notebook involves the creation of a new column that categorizes each type of product, providing a categorical overview for better analysis.

### 4. check_outliers.ipynb
- The notebook deals with identifying and handling outliers in the dataset.

## How to Use

### Initial Explorations
- **initial_exploring.ipynb:** To explore the dataset, open this notebook in Jupyter. Run each cell sequentially to visualize key aspects of the dataset. Comments in the notebook provide guidance and insights at each step.

### Data Preprocessing
- **data_processingNo23.ipynb:** This notebook demonstrates how to preprocess the dataset into two distinct CSV files based on the temporal aspect. Follow the commented instructions within the notebook to execute the preprocessing steps.

### Product Categorization
- **creating_product_category.ipynb:** Open this notebook to add a new column for product categorization. The commented sections in the notebook guide the process of creating and assigning categories to different types of products.

### Outlier Detection and Handling
- **check_outliers.ipynb:** This notebook provides a method to identify and handle outliers in the dataset. Follow the commented instructions to understand and manage outliers effectively.

## Purpose

These notebooks cover various stages of data exploration and preprocessing, serving as essential steps in understanding, cleaning, and preparing the dataset for further analysis and modeling.

---

*Note: Ensure the necessary libraries and dependencies are installed to run these notebooks in a Jupyter environment.*
